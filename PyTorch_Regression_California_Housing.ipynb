{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "LBz5Q8GPNY5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(test_size=0.2, random_state=42):\n",
        "\n",
        "    # Load California Housing dataset\n",
        "    data = fetch_california_housing()\n",
        "    X, y = data.data, data.target\n",
        "\n",
        "    # Split into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "    y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "sk3bATFsNdPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ],
      "metadata": {
        "id": "yxNHQeJ2Nlf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for X_batch, y_batch in loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "    return running_loss / len(loader.dataset)"
      ],
      "metadata": {
        "id": "bZZoZbZ2Npke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            running_loss += loss.item() * X_batch.size(0)\n",
        "    return running_loss / len(loader.dataset)"
      ],
      "metadata": {
        "id": "S8q0VqbkNtoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Hyperparameters\n",
        "    batch_size = 64\n",
        "    lr = 1e-3\n",
        "    epochs = 50\n",
        "    test_size = 0.2\n",
        "\n",
        "    # Device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load data\n",
        "    X_train, X_test, y_train, y_test = load_data(test_size=test_size)\n",
        "\n",
        "    # DataLoader\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    test_dataset = TensorDataset(X_test, y_test)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Model, loss, optimizer\n",
        "    model = RegressionModel(input_dim=X_train.shape[1]).to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "        test_loss = evaluate(model, test_loader, criterion, device)\n",
        "        print(f'Epoch {epoch:03d}: Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}')\n",
        "\n",
        "    # Save the trained model\n",
        "    torch.save(model.state_dict(), 'regression_model.pth')\n",
        "    print('Training complete. Model saved to regression_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXCkWovyN832",
        "outputId": "4f03fe43-ef32-4aea-b8de-d4266f4134e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001: Train Loss: 1.4157 | Test Loss: 0.5344\n",
            "Epoch 002: Train Loss: 0.4613 | Test Loss: 0.4712\n",
            "Epoch 003: Train Loss: 0.4233 | Test Loss: 0.4225\n",
            "Epoch 004: Train Loss: 0.4020 | Test Loss: 0.4150\n",
            "Epoch 005: Train Loss: 0.4504 | Test Loss: 0.4004\n",
            "Epoch 006: Train Loss: 0.3855 | Test Loss: 0.3787\n",
            "Epoch 007: Train Loss: 0.3616 | Test Loss: 0.3687\n",
            "Epoch 008: Train Loss: 0.3519 | Test Loss: 0.3621\n",
            "Epoch 009: Train Loss: 0.3447 | Test Loss: 0.3499\n",
            "Epoch 010: Train Loss: 0.3378 | Test Loss: 0.3456\n",
            "Epoch 011: Train Loss: 0.3351 | Test Loss: 0.3377\n",
            "Epoch 012: Train Loss: 0.3299 | Test Loss: 0.3355\n",
            "Epoch 013: Train Loss: 0.3225 | Test Loss: 0.3260\n",
            "Epoch 014: Train Loss: 0.3183 | Test Loss: 0.3237\n",
            "Epoch 015: Train Loss: 0.3209 | Test Loss: 0.3180\n",
            "Epoch 016: Train Loss: 0.3117 | Test Loss: 0.3148\n",
            "Epoch 017: Train Loss: 0.3086 | Test Loss: 0.3264\n",
            "Epoch 018: Train Loss: 0.3019 | Test Loss: 0.3213\n",
            "Epoch 019: Train Loss: 0.3013 | Test Loss: 0.3109\n",
            "Epoch 020: Train Loss: 0.3018 | Test Loss: 0.3075\n",
            "Epoch 021: Train Loss: 0.3278 | Test Loss: 0.3087\n",
            "Epoch 022: Train Loss: 0.2992 | Test Loss: 0.3063\n",
            "Epoch 023: Train Loss: 0.2982 | Test Loss: 0.3034\n",
            "Epoch 024: Train Loss: 0.3043 | Test Loss: 0.3006\n",
            "Epoch 025: Train Loss: 0.2908 | Test Loss: 0.3006\n",
            "Epoch 026: Train Loss: 0.2930 | Test Loss: 0.2992\n",
            "Epoch 027: Train Loss: 0.2890 | Test Loss: 0.2981\n",
            "Epoch 028: Train Loss: 0.2874 | Test Loss: 0.2999\n",
            "Epoch 029: Train Loss: 0.2877 | Test Loss: 0.2950\n",
            "Epoch 030: Train Loss: 0.2897 | Test Loss: 0.3018\n",
            "Epoch 031: Train Loss: 0.2829 | Test Loss: 0.2921\n",
            "Epoch 032: Train Loss: 0.2848 | Test Loss: 0.2969\n",
            "Epoch 033: Train Loss: 0.2838 | Test Loss: 0.2968\n",
            "Epoch 034: Train Loss: 0.2878 | Test Loss: 0.2967\n",
            "Epoch 035: Train Loss: 0.2811 | Test Loss: 0.3029\n",
            "Epoch 036: Train Loss: 0.2781 | Test Loss: 0.2916\n",
            "Epoch 037: Train Loss: 0.2779 | Test Loss: 0.2908\n",
            "Epoch 038: Train Loss: 0.2870 | Test Loss: 0.2940\n",
            "Epoch 039: Train Loss: 0.2778 | Test Loss: 0.3049\n",
            "Epoch 040: Train Loss: 0.2759 | Test Loss: 0.2917\n",
            "Epoch 041: Train Loss: 0.2788 | Test Loss: 0.2933\n",
            "Epoch 042: Train Loss: 0.2728 | Test Loss: 0.3024\n",
            "Epoch 043: Train Loss: 0.2728 | Test Loss: 0.2879\n",
            "Epoch 044: Train Loss: 0.2714 | Test Loss: 0.2854\n",
            "Epoch 045: Train Loss: 0.2716 | Test Loss: 0.2861\n",
            "Epoch 046: Train Loss: 0.2726 | Test Loss: 0.2875\n",
            "Epoch 047: Train Loss: 0.2759 | Test Loss: 0.2831\n",
            "Epoch 048: Train Loss: 0.2698 | Test Loss: 0.2874\n",
            "Epoch 049: Train Loss: 0.2702 | Test Loss: 0.2853\n",
            "Epoch 050: Train Loss: 0.2691 | Test Loss: 0.2898\n",
            "Training complete. Model saved to regression_model.pth\n"
          ]
        }
      ]
    }
  ]
}